{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Assignment 3:  Decision Tree Implementation\n",
    "*Margaret Thomann - February 17, 2018 *\n",
    "\n",
    "In this assignment, I will construct a decision tree from the data provided about heart disease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Reading the data and assigning counts to arrays and Data class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Data Class \n",
    "A Data class will be instantiated for each line of the data.  It will then be added to one of two arrays (explained later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "class Data:\n",
    "    def __init__(self, has_heart_disease_value):\n",
    "        self.has_heart_disease = has_heart_disease_value\n",
    "        self.data_vars = OrderedDict()\n",
    "        self.data_vars[\"age\"] = 0\n",
    "        self.data_vars[\"sex\"] = 0\n",
    "        self.data_vars[\"chest_pain_type\"] = 0\n",
    "        self.data_vars[\"resting_blood_pressure\"] = 0\n",
    "        self.data_vars[\"serum_cholesterol\"] = 0\n",
    "        self.data_vars[\"fasting_blood_sugar\"] = 0\n",
    "        self.data_vars[\"resting_electrocardiographic_results\"] = 0\n",
    "        self.data_vars[\"maximum_heart_rate_achieved\"] = 0\n",
    "        self.data_vars[\"exercise_induced_angina\"] = 0\n",
    "        self.data_vars[\"oldpeak\"] = 0\n",
    "        self.data_vars[\"slope_peak_exercise\"] = 0\n",
    "        self.data_vars[\"number_of_major_vessels\"] = 0\n",
    "        self.data_vars[\"thal\"] = 0\n",
    "        self.data_vars[\"has_heart_disease\"] = self.has_heart_disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 = # Of People with Heart Disease\n",
      "150 = # Of People without Heart Disease\n"
     ]
    }
   ],
   "source": [
    "# Arrays for the Data instances\n",
    "#     absence_heart_array  : contains all Data instantiations where heart disease is absent\n",
    "#     presence_heart_array : contains all Data instantiations where heart disease is absent\n",
    "absence_heart_array = []\n",
    "presence_heart_array = []\n",
    "total_data_array = []\n",
    "\n",
    "data = open('heart.data.txt')\n",
    "for line in data.readlines():\n",
    "    feature_value_list = line.split()\n",
    "    has_heart_disease = int(feature_value_list[-1])\n",
    "    data = Data(has_heart_disease)\n",
    "    counter = 0\n",
    "    for feature in data.data_vars.keys():\n",
    "        data.data_vars[feature] = float(feature_value_list[counter])\n",
    "        counter += 1\n",
    "    if has_heart_disease == 2:\n",
    "        presence_heart_array.append(data)\n",
    "    elif has_heart_disease == 1:\n",
    "        absence_heart_array.append(data)\n",
    "    total_data_array.append(data)\n",
    "\n",
    "presence_heart_array_num = len(presence_heart_array)\n",
    "absence_heart_array_num = len(absence_heart_array)\n",
    "print str(presence_heart_array_num) + \" = # Of People with Heart Disease\"\n",
    "print str(absence_heart_array_num) + \" = # Of People without Heart Disease\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Calculate Information Gain for Each Feature\n",
    "The below function can be used to determine the information gain for a given data and hypothesis (passed in as a string - x and y).  Information Gain can be represented as: Infgain(Y|X_K) = H(Y) - H(Y|X_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def info_gain_buckets(y, x, buckets, bucket_num):\n",
    "    print \"info_gain_bucket called with \"+ str(len(buckets)) + \" buckets\"\n",
    "    \n",
    "    # Define dicts for the counts\n",
    "    positive_y_counts = {}\n",
    "    positive_x_counts = {}\n",
    "    negative_y_counts = {}\n",
    "    negative_x_counts = {}\n",
    "    \n",
    "    # Get the bucket values\n",
    "    for bucket in buckets:\n",
    "        # Convert to string\n",
    "        s = \"\"\n",
    "        for num in list(set(bucket)):\n",
    "            s += (str(num)+ \" \")\n",
    "        positive_x_counts[s] = 0\n",
    "        negative_x_counts[s] = 0        \n",
    "\n",
    "    \n",
    "    y_denom = 0\n",
    "    for data in presence_heart_array:\n",
    "        y_denom += 1\n",
    "        value = data.data_vars[y]\n",
    "        \n",
    "        # Value is not in dictionary yet\n",
    "        # so set the occurence for that value to 1\n",
    "        if value not in positive_y_counts.keys():\n",
    "            positive_y_counts[value] = 1 \n",
    "        # Value is already in dictionary\n",
    "        # so increase the occurence count for that value by 1\n",
    "        else:\n",
    "            current_count_for_value = positive_y_counts[value]\n",
    "            positive_y_counts.update({value:current_count_for_value+1})\n",
    "            \n",
    "        # Same thing is done for processing x:\n",
    "        x_value = data.data_vars[x]\n",
    "        for key in negative_x_counts.keys():\n",
    "            if str(x_value)+\" \" in key:\n",
    "                current_count_for_value = positive_x_counts[key]\n",
    "                positive_x_counts.update({key:current_count_for_value+1})\n",
    "            \n",
    "    \n",
    "    for data in absence_heart_array:\n",
    "        y_denom += 1\n",
    "        value = data.data_vars[y]\n",
    "        \n",
    "        # Value is not in dictionary yet\n",
    "        # so set the occurence for that value to 1\n",
    "        if value not in negative_y_counts.keys():\n",
    "            negative_y_counts[value] = 1 \n",
    "        # Value is already in dictionary\n",
    "        # so increase the occurence count for that value by 1\n",
    "        else:\n",
    "            current_count_for_value = negative_y_counts[value]\n",
    "            negative_y_counts.update({value:current_count_for_value+1})\n",
    "            \n",
    "        # Same thing is done for processing x:\n",
    "        x_value = data.data_vars[x]\n",
    "        for key in negative_x_counts.keys():\n",
    "            if str(x_value)+\" \" in key:\n",
    "                current_count_for_value = negative_x_counts[key]\n",
    "                negative_x_counts.update({key:current_count_for_value+1})\n",
    "            \n",
    "            \n",
    "    # Calculate H(Y)     \n",
    "    h_of_y = 0\n",
    "    for count in positive_y_counts.values():\n",
    "        p = float(float(count)/float(y_denom))\n",
    "        entropy = -1 * p * (math.log(p, 2))\n",
    "        h_of_y += entropy\n",
    "    for count in negative_y_counts.values():\n",
    "        p = float(float(count)/float(y_denom))\n",
    "        entropy = -1 * p * (math.log(p, 2))\n",
    "        h_of_y += entropy\n",
    "    \n",
    "    h_of_y_given_x = 0\n",
    "    for feature_value in positive_x_counts.keys():\n",
    "        sum_of_values = positive_x_counts[feature_value] + negative_x_counts[feature_value]\n",
    "        fraction = float(float(sum_of_values)/float(y_denom))\n",
    "        p_positive = float(float(positive_x_counts[feature_value])/float(sum_of_values)) \n",
    "        p_negative = float(float(negative_x_counts[feature_value])/float(sum_of_values)) \n",
    "        entropy_positive = -p_positive * (math.log(p_positive, 2))\n",
    "        entropy_negative = -p_negative * (math.log(p_negative, 2))\n",
    "        h_of_y_given_x -= fraction*(entropy_positive+entropy_negative)\n",
    "    \n",
    "    info_gain = h_of_y - h_of_y_given_x\n",
    "    return info_gain\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Determine possible splits\n",
    "These will be used for the information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_splits(feature):\n",
    "    splits = {}\n",
    "    already_split_on = []\n",
    "    for data in total_data_array:\n",
    "        feature_value = float(data.data_vars[feature])\n",
    "        if feature_value not in already_split_on:\n",
    "            already_split_on.append(feature_value)\n",
    "            splits[feature_value] = [[],[]]\n",
    "    \n",
    "    for split in splits:\n",
    "        less_than_array = []\n",
    "        greater_than_or_equal_to_array = []\n",
    "        for data in total_data_array:\n",
    "            feature_value = float(data.data_vars[feature])\n",
    "            # Compare it to the split\n",
    "            if feature_value < split:\n",
    "                less_than_array.append(feature_value)\n",
    "            else:\n",
    "                greater_than_or_equal_to_array.append(feature_value)\n",
    "        splits[split] = [less_than_array,greater_than_or_equal_to_array]\n",
    "    \n",
    "    # Remove any splits where the less than array is 0\n",
    "    \n",
    "    split_dict = {}\n",
    "    for data in total_data_array: \n",
    "        feature_value = float(data.data_vars[feature])\n",
    "        if feature_value not in split_dict.keys():\n",
    "            new_list = []\n",
    "            new_list.append(feature_value)\n",
    "            split_dict[feature_value] = new_list\n",
    "        else:\n",
    "            split_dict[feature_value].append(feature_value)\n",
    "    \n",
    "    \n",
    "\n",
    "    for split in splits.keys():\n",
    "        if len(splits[split][0]) == 0:\n",
    "            del splits[split]\n",
    "            break\n",
    "            \n",
    "    separate_buckets = []\n",
    "    for l in split_dict.values():\n",
    "        separate_buckets.append(l)\n",
    "    \n",
    "    splits[\"separate_values\"] = separate_buckets\n",
    "\n",
    "    \n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def compute_best_split(feature):\n",
    "    print \"Computing best split for: \"+feature\n",
    "    splits = get_splits(feature)\n",
    "    info_gains = {}\n",
    "    max_split_info = 0\n",
    "    split_on_value = 0\n",
    "    for split in splits.keys():\n",
    "        info_gains[split] = info_gain_buckets(\"has_heart_disease\", feature, splits[split], len(splits[split]))\n",
    "        print str(info_gains[split])+\" = info gain for splitting on \"+str(split)\n",
    "        if info_gains[split] > max_split_info:\n",
    "            max_split_info = info_gains[split]\n",
    "            split_on_value = split\n",
    "    return {\"Greatest Info Gain\":max_split_info,\n",
    "           \"from splitting on value\":split_on_value}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Recurse to build the tree\n",
    "Used the information gain function to determine the best splits for each node of the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_tree():\n",
    "    for feature in data.data_vars.keys():\n",
    "        print compute_best_split(\"thal\")\n",
    "        #information_gain = info_gain(\"has_heart_disease\", feature)\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best split for: thal\n",
      "info_gain_bucket called with 3 buckets\n",
      "1.77359644136 = info gain for splitting on separate_values\n",
      "info_gain_bucket called with 2 buckets\n",
      "1.7791218833 = info gain for splitting on 6.0\n",
      "info_gain_bucket called with 2 buckets\n",
      "1.79338911416 = info gain for splitting on 7.0\n",
      "{'Greatest Info Gain': 1.793389114163413, 'from splitting on value': 7.0}\n"
     ]
    }
   ],
   "source": [
    "build_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
