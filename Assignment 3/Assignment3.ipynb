{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Assignment 3:  Decision Tree Implementation\n",
    "*Margaret Thomann - February 17, 2018 *\n",
    "\n",
    "In this assignment, I will construct a decision tree from the data provided about heart disease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Reading the data and assigning counts to arrays and Data class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Data Class \n",
    "A Data class will be instantiated for each line of the data.  It will then be added to one of two arrays (explained later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4167,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "class Data:\n",
    "    def __init__(self, class_value):\n",
    "        self.class_value = class_value\n",
    "        self.data_vars = OrderedDict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Calculate Information Gain for Each Feature\n",
    "The below function can be used to determine the information gain for a given data and hypothesis (passed in as a string - x and y).  Information Gain can be represented as: Infgain(Y|X_K) = H(Y) - H(Y|X_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4168,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Data processed\n",
      "-----------------\n",
      "\t120 = # Of People with Heart Disease\n",
      "\t150 = # Of People without Heart Disease\n"
     ]
    }
   ],
   "source": [
    "# Arrays for the Data instances\n",
    "#     absence_heart_array  : contains all Data instantiations where heart disease is absent\n",
    "#     presence_heart_array : contains all Data instantiations where heart disease is absent\n",
    "absence_heart_array = []\n",
    "presence_heart_array = []\n",
    "total_data_array = []\n",
    "\n",
    "# Classify the features according to their type: nominal or continuous\n",
    "indices_for_nominal = [10, 1, 5, 8, 6, 2, 12]\n",
    "indices_for_continuous = [0,3,4,7,9,11]\n",
    "feature_names = [\"age\", \"sex\", \"chest_pain_type\", \"resting_blood_pressure\", \"serum_cholesterol\", \"fasting_blood_sugar\",\n",
    "                \"resting_electrocardiographic_results\", \"maximum_heart_rate_achieved\", \"exercise_induced_angina\",\n",
    "                \"oldpeak\", \"slope_peak_exercise\", \"number_of_major_vessels\", \"thal\", \"has_heart_disease\"]\n",
    "features_and_types = OrderedDict()\n",
    "for feature in feature_names:\n",
    "    if feature_names.index(feature) in indices_for_continuous:\n",
    "        features_and_types[feature] = \"continuous\"\n",
    "    else:\n",
    "        features_and_types[feature] = \"nominal\"\n",
    "\n",
    "# Process the data and store it in the arrays\n",
    "data = open('heart.data.txt')\n",
    "for line in data.readlines():\n",
    "    feature_value_list = line.split()\n",
    "    has_heart_disease = int(feature_value_list[-1])\n",
    "    data = Data(has_heart_disease)\n",
    "    counter = 0\n",
    "    feature_dict = OrderedDict()\n",
    "    for feature in feature_value_list:\n",
    "        data.data_vars[feature_names[counter]] = float(feature)\n",
    "        counter += 1\n",
    "    if has_heart_disease == 2:\n",
    "        presence_heart_array.append(data)\n",
    "    elif has_heart_disease == 1:\n",
    "        absence_heart_array.append(data)\n",
    "    total_data_array.append(data)\n",
    "\n",
    "presence_heart_array_num = len(presence_heart_array)\n",
    "absence_heart_array_num = len(absence_heart_array)\n",
    "print \"✔ Data processed\"\n",
    "print \"-----------------\"\n",
    "print \"\\t\" + str(presence_heart_array_num) + \" = # Of People with Heart Disease\"\n",
    "print \"\\t\" + str(absence_heart_array_num) + \" = # Of People without Heart Disease\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Printer Function to Print out Data\n",
    "The below function can be called with a Data object as its input to print out that data objects contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_data(data_obj):\n",
    "    print \"_____________\"\n",
    "    for feature in data_obj.data_vars.keys():\n",
    "        print data_obj.data_vars[feature], \": \", feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4170,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def compute_info_gain(y, y_values, x, buckets, considered_data):\n",
    "        \n",
    "    '''\n",
    "    if x == \"sex\":\n",
    "        print \"sex vals!!!\"\n",
    "        for data_point in considered_data:\n",
    "            print data_point.data_vars[\"sex\"]\n",
    "        #print \"y_values:\"\n",
    "        #print y_values\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    if y == \"chest_pain_type\":\n",
    "        print \"y_values:\"\n",
    "        print y_values\n",
    "    '''\n",
    "    \n",
    "    #print \"Calling compute_info_gain with y = \"+y+\" and x = \"+x\n",
    "    \n",
    "        \n",
    "    # Define dicts for the counts\n",
    "    positive_y_counts = {}\n",
    "    positive_x_counts = {}\n",
    "    negative_y_counts = {}\n",
    "    negative_x_counts = {}\n",
    "    \n",
    "    # Get the bucket values\n",
    "    for bucket in buckets:\n",
    "        # Convert to string\n",
    "        s = \"\"\n",
    "        for num in list(set(bucket)):\n",
    "            s += (str(num)+ \" \")\n",
    "        positive_x_counts[s] = 0\n",
    "        negative_x_counts[s] = 0\n",
    "    \n",
    "    \n",
    "    for val in y_values:\n",
    "        positive_y_counts[str(float(val))] = 0\n",
    "        negative_y_counts[str(float(val))] = 0\n",
    "    \n",
    "    y_denom = 0\n",
    "    for data in considered_data:\n",
    "        y_denom += 1\n",
    "        has_heart_disease = data.data_vars[\"has_heart_disease\"]\n",
    "        y_value = data.data_vars[y]\n",
    "        x_value = data.data_vars[x]\n",
    "        array_x = []\n",
    "        array_y = []\n",
    "        if has_heart_disease == 1:\n",
    "            # Update all of the negative arrays\n",
    "            array_x = negative_x_counts\n",
    "            array_y = negative_y_counts\n",
    "        elif has_heart_disease == 2:\n",
    "            # Update all of the positive arrays\n",
    "            array_x = positive_x_counts\n",
    "            array_y = positive_y_counts\n",
    "            \n",
    "        # Value is not in dictionary yet\n",
    "        # so set the occurrence for that value to 1\n",
    "        '''\n",
    "        if value not in array_y.keys():\n",
    "            array_y[y_value] = 1 \n",
    "        # Value is already in dictionary\n",
    "        # so increase the occurrence count for that value by 1\n",
    "        else:\n",
    "            current_count_for_value = array_y[y_value]\n",
    "            array_y.update({y_value:current_count_for_value+1})\n",
    "        '''\n",
    "        for key in array_x.keys():\n",
    "            if str(x_value)+\" \" in key:\n",
    "                current_count_for_value = array_x[key]\n",
    "                array_x.update({key:current_count_for_value+1})\n",
    "                \n",
    "        for key in array_y.keys():\n",
    "            if str(y_value) in key:\n",
    "                current_count_for_value = array_y[key]\n",
    "                array_y.update({key:current_count_for_value+1})\n",
    "\n",
    "    '''\n",
    "    y_denom = 0\n",
    "    \n",
    "    for data in presence_heart_array:\n",
    "        y_denom += 1\n",
    "        value = data.data_vars[y]\n",
    "        \n",
    "        # Value is not in dictionary yet\n",
    "        # so set the occurrence for that value to 1\n",
    "        if value not in positive_y_counts.keys():\n",
    "            positive_y_counts[value] = 1 \n",
    "        # Value is already in dictionary\n",
    "        # so increase the occurrence count for that value by 1\n",
    "        else:\n",
    "            current_count_for_value = positive_y_counts[value]\n",
    "            positive_y_counts.update({value:current_count_for_value+1})\n",
    "            \n",
    "        # Same thing is done for processing x:\n",
    "        x_value = data.data_vars[x]\n",
    "        for key in positive_x_counts.keys():\n",
    "            if str(x_value)+\" \" in key:\n",
    "                current_count_for_value = positive_x_counts[key]\n",
    "                positive_x_counts.update({key:current_count_for_value+1})\n",
    "            \n",
    "    \n",
    "    for data in absence_heart_array:\n",
    "        y_denom += 1\n",
    "        value = data.data_vars[y]\n",
    "        \n",
    "        # Value is not in dictionary yet\n",
    "        # so set the occurrence for that value to 1\n",
    "        if value not in negative_y_counts.keys():\n",
    "            negative_y_counts[value] = 1 \n",
    "        # Value is already in dictionary\n",
    "        # so increase the occurrence count for that value by 1\n",
    "        else:\n",
    "            current_count_for_value = negative_y_counts[value]\n",
    "            negative_y_counts.update({value:current_count_for_value+1})\n",
    "            \n",
    "        # Same thing is done for processing x:\n",
    "        x_value = data.data_vars[x]\n",
    "        for key in negative_x_counts.keys():\n",
    "            if str(x_value)+\" \" in key:\n",
    "                current_count_for_value = negative_x_counts[key]\n",
    "                negative_x_counts.update({key:current_count_for_value+1})\n",
    "                \n",
    "    '''\n",
    "    '''\n",
    "    if x == \"sex\":\n",
    "        print \"postive_y_counts array\"\n",
    "        print positive_y_counts\n",
    "        print \"negative_y_counts array\"\n",
    "        print negative_y_counts\n",
    "    '''   \n",
    "            \n",
    "    h_of_y = 0\n",
    "    for count in positive_y_counts.values():\n",
    "        '''\n",
    "        if y == \"chest_pain_type\":\n",
    "            print \"positive_y_count: \"+str(count)\n",
    "        '''\n",
    "        \n",
    "        entropy = 0\n",
    "        if count != 0:\n",
    "            p = float(float(count)/float(y_denom))\n",
    "            entropy = -1 * p * (math.log(p, 2))\n",
    "        h_of_y += entropy\n",
    "    for count in negative_y_counts.values():\n",
    "\n",
    "        '''\n",
    "        if y == \"chest_pain_type\":\n",
    "            print \"negative_y_count: \"+str(count)\n",
    "        '''\n",
    "    \n",
    "        entropy = 0\n",
    "        if count != 0:\n",
    "            p = float(float(count)/float(y_denom))\n",
    "            entropy = -1 * p * (math.log(p, 2))\n",
    "        h_of_y += entropy\n",
    "    \n",
    "    h_of_y_given_x = 0\n",
    "    for feature_value in positive_x_counts.keys():\n",
    "        '''\n",
    "        if x == \"sex\":\n",
    "            print \"positive_x_counts: \"+str(positive_x_counts[feature_value])+\" for feature value: \"+str(feature_value)\n",
    "            print \"negative_x_counts: \"+str(negative_x_counts[feature_value])+\" for feature value: \"+str(feature_value)        \n",
    "        '''\n",
    "        entropy_positive = 0\n",
    "        entropy_negative = 0\n",
    "        sum_of_values = positive_x_counts[feature_value] + negative_x_counts[feature_value] \n",
    "        fraction = float(float(sum_of_values)/float(y_denom))\n",
    "        if positive_x_counts[feature_value] != 0:\n",
    "            p_positive = float(float(positive_x_counts[feature_value])/float(sum_of_values)) \n",
    "            entropy_positive = p_positive * (math.log(p_positive, 2))\n",
    "        if negative_x_counts[feature_value] != 0:\n",
    "            p_negative = float(float(negative_x_counts[feature_value])/float(sum_of_values)) \n",
    "            entropy_negative = p_negative * (math.log(p_negative, 2))\n",
    "        \n",
    "        h_of_y_given_x += fraction*(entropy_positive+entropy_negative)\n",
    "    \n",
    "    '''\n",
    "    if x == \"sex\":\n",
    "        print \"h_of_y:\"+str(h_of_y)\n",
    "        print \"h_of_y_given_x:\"+str(h_of_y_given_x)\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    if h_of_y_given_x < 0:\n",
    "        info_gain = h_of_y - (h_of_y_given_x)\n",
    "        return info_gain\n",
    "    else:\n",
    "        info_gain = h_of_y - (-1*h_of_y_given_x)\n",
    "        return info_gain\n",
    "    '''\n",
    "    #print \"h of y: \", h_of_y\n",
    "    #print \"h of y given x: \", h_of_y_given_x\n",
    "    info_gain = h_of_y + h_of_y_given_x\n",
    "    return info_gain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Utility Function used to generate all of the possible splits\n",
    "Credit:  https://stackoverflow.com/questions/19368375/set-partitions-in-python/30134039#30134039"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4171,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def partition(collection):\n",
    "    if len(collection) == 1:\n",
    "        yield [ collection ]\n",
    "        return\n",
    "\n",
    "    first = collection[0]\n",
    "    for smaller in partition(collection[1:]):\n",
    "        # insert `first` in each of the subpartition's subsets\n",
    "        for n, subset in enumerate(smaller):\n",
    "            yield smaller[:n] + [[ first ] + subset]  + smaller[n+1:]\n",
    "        # put `first` in its own subset \n",
    "        yield [ [ first ] ] + smaller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Determine possible splits\n",
    "These will be used for the information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4172,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# get_continuous_binary_split(feature):     \n",
    "#    Gets a feature and splits the data for that feature in all the possible ways to split that\n",
    "#    data into two buckets.  It returns a dictionary where the key is the number it split on and the\n",
    "#    value is a list of two lists.  The first element of the list is all of the elements less than\n",
    "#    the split and the second element of the list is a list of all of the elements greater than or\n",
    "#    equal to the split.\n",
    "#    For example:\n",
    "#           feature = \"age\"\n",
    "#           splits_dict = {50: [[20,40,43...],[50,60,61...]], 60: [[57,45,59...],[60,61,63...]]}\n",
    "def get_continuous_binary_split(feature, considered_data):\n",
    "    # Ensure the function is being called only with continuous features\n",
    "    if features_and_types[feature] != \"continuous\":\n",
    "        raise ValueError('Error in get_continuous_binary_split: input feature is not continuous.')\n",
    "        return\n",
    "    \n",
    "    # Create a list of the possible splits\n",
    "    splits = []\n",
    "    counts_for_feature_values = {}\n",
    "    \n",
    "    #print \"The Length of the Considered Data: \",len(considered_data)\n",
    "    \n",
    "    for data in considered_data:\n",
    "        feature_value = float(data.data_vars[feature])\n",
    "        if feature_value not in splits:\n",
    "            splits.append(feature_value)\n",
    "        if feature_value not in counts_for_feature_values:\n",
    "            counts_for_feature_values[feature_value] = 1\n",
    "        else:\n",
    "            current = counts_for_feature_values[feature_value]\n",
    "            counts_for_feature_values[feature_value] = current + 1\n",
    "    \n",
    "    # Process the splits and create the less than list and greater than or equal to list for each\n",
    "    splits_list = []\n",
    "    for split in splits:\n",
    "        lt_split_feature_values = []\n",
    "        gtequal_split_feature_values = []\n",
    "        for data in considered_data:\n",
    "            feature_value = float(data.data_vars[feature])\n",
    "            if feature_value < split:\n",
    "                lt_split_feature_values.append(feature_value)\n",
    "            else:\n",
    "                gtequal_split_feature_values.append(feature_value)\n",
    "        #if len(lt_split_feature_values) != 0:\n",
    "        splits_list.append([lt_split_feature_values, gtequal_split_feature_values])\n",
    "            \n",
    "    # Generate a list of partition dicts\n",
    "    # Each list element will be a list of dictionaries\n",
    "    # The dictionaries will contain the feature_value and the number of times it occurs\n",
    "    # The list of these dictionaries will be split up by partition\n",
    "    partitions_and_values = []\n",
    "    for partition in splits_list:\n",
    "        split_inclusive = []\n",
    "        for l in partition:\n",
    "            set_l = set(l)\n",
    "            count_dict = {}\n",
    "            for feature_value in set_l:\n",
    "                num_of_feature_value_occurrences = counts_for_feature_values[feature_value]\n",
    "                count_dict[feature_value] = num_of_feature_value_occurrences\n",
    "            split_inclusive.append(count_dict)\n",
    "        partitions_and_values.append(split_inclusive)\n",
    "            \n",
    "    return partitions_and_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4173,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "# get_nominal_split(feature):     \n",
    "#    Gets a nominal feature and splits the data for that feature in all the possible ways to split that\n",
    "#    data into every possible number of buckets.  It returns a dictionary where the key is the number it \n",
    "#    split on and the value is a list of the lists it generated from the split.  \n",
    "\n",
    "def split_list(data, n):\n",
    "    from itertools import combinations, chain\n",
    "    for splits in combinations(range(1, len(data)), n-1):\n",
    "        result = []\n",
    "        prev = None\n",
    "        for split in chain(splits, [None]):\n",
    "            result.append(data[prev:split])\n",
    "            prev = split\n",
    "        yield result\n",
    "        \n",
    "def get_nominal_split(feature, considered_data):\n",
    "    # Ensure the function is being called only with nominal features\n",
    "    if features_and_types[feature] != \"nominal\":\n",
    "        raise ValueError('Error in get_nominal_split: input feature is not nominal.')\n",
    "        return\n",
    "    \n",
    "    #print \"get_nominal_split called with feature: \"+feature\n",
    "    # Determine the unique values for the feature and the counts for the feature_value\n",
    "    splits = {}\n",
    "    split_nums = []\n",
    "    for data in considered_data:\n",
    "        feature_value = float(data.data_vars[feature])\n",
    "        if feature_value not in splits:\n",
    "            split_nums.append(feature_value)\n",
    "            splits[feature_value] = 1\n",
    "        else:\n",
    "            current_num = splits[feature_value]\n",
    "            splits[feature_value] = current_num+1\n",
    "    \n",
    "    #print \"possible values for feature:\"\n",
    "    #print split_nums\n",
    "\n",
    "    # Generate all the possible ways to partition the numbers  \n",
    "    # possible_partitions is a list of tuples where the first element of the tuple\n",
    "    # is the kth possible partition and the second element of the tuple is a list\n",
    "    # of lists of partitions\n",
    "    possible_partitions = []\n",
    "    for p in partition(split_nums):\n",
    "        # Be sure to remove the split where all values are placed in one bucket\n",
    "        if (len(sorted(p)) != 1) or ((len(sorted(p)) == 1) and (len(split_nums) == 1)):\n",
    "            possible_partitions.append(sorted(p))\n",
    "    #print \"possible_partitions:\"\n",
    "    #print possible_partitions\n",
    "                \n",
    "    # Generate a list of partition dicts\n",
    "    # Each list element will be a list of dictionaries\n",
    "    # The dictionaries will contain the feature_value and the number of times it occurs\n",
    "    # The list of these dictionaries will be split up by partition\n",
    "    partitions_and_values = []\n",
    "    for split_lists in possible_partitions:\n",
    "        split_dicts = []\n",
    "        for bucket in split_lists:\n",
    "            bucket_dict = {}\n",
    "            for feature_value in bucket:\n",
    "                num_of_feature_value_occurrences = splits[feature_value]\n",
    "                bucket_dict[feature_value] = num_of_feature_value_occurrences\n",
    "            split_dicts.append(bucket_dict)\n",
    "        partitions_and_values.append(split_dicts)\n",
    "    return partitions_and_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the best split\n",
    "Checks the information gain for all the possible splits for a certain feature and reports the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4174,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def compute_best_split(y, y_values, feature, considered_data):\n",
    "    # Check if the feature is nominal or continuous and split accordingly\n",
    "    splits = []\n",
    "    if features_and_types[feature] == \"nominal\":\n",
    "        \n",
    "        splits = get_nominal_split(feature, considered_data)\n",
    "    else:\n",
    "        splits = get_continuous_binary_split(feature, considered_data)\n",
    "    \n",
    "    # Create a dictionary where the key is the information gain from a particular\n",
    "    # split and the value is that particular split\n",
    "    info_gains = {}\n",
    "    for split in splits:\n",
    "        info_gain = compute_info_gain(y, y_values, feature, split, considered_data)\n",
    "        info_gains[info_gain] = split\n",
    "        \n",
    "    # Process the dictionary and determine the highest info gain\n",
    "    #print \"info-gains\"\n",
    "    #print \"compute_best_info_gain called with: \"+feature\n",
    "    #print \"considered_data\"\n",
    "    #print considered_data\n",
    "    #print info_gains\n",
    "    max_info_gain = max(info_gains, key=float)\n",
    "    split_yielding_max_info_gain = info_gains[max_info_gain]\n",
    "    \n",
    "    # Print the maximum info gain and corresponding split\n",
    "    #print \"FEATURE: \"+feature\n",
    "    #print \"Greatest Info Gain is: \"+str(max_info_gain)\n",
    "    #print \"from split:\"\n",
    "    #for split in split_yielding_max_info_gain:\n",
    "        #print sorted(set(split))\n",
    "    return max_info_gain, split_yielding_max_info_gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree Class\n",
    "Set up classes for the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    def __init__(self, splitting_feature, feature_value, feature_value_occurrence, data):\n",
    "        self.splitting_feature = splitting_feature\n",
    "        self.feature_value = feature_value\n",
    "        self.feature_value_occurrence = feature_value_occurrence\n",
    "        self.data = data\n",
    "        self.children = []\n",
    "\n",
    "    def add_child(self, obj):\n",
    "        self.children.append(obj)\n",
    "        \n",
    "    def print_node(self, node):\n",
    "        print \"\\t splitting_feature: \", node.splitting_feature\n",
    "        print \"\\t feature_value: \", node.feature_value\n",
    "        print \"\\t feature_value_occurrence: \", node.feature_value_occurrence\n",
    "    \n",
    "    def print_children(self):\n",
    "        counter = 1\n",
    "        for child in self.children:\n",
    "            print counter, \":\"\n",
    "            self.print_node(child)\n",
    "            counter += 1\n",
    "    \n",
    "    def print_node_and_children(self):\n",
    "        print \"*   NODE  *\"\n",
    "        self.print_node(self)\n",
    "        print \"* CHILDREN *\"\n",
    "        self.print_children()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data\n",
    "Split the data and return a list of arrays of the split data given the feature and the splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_data(feature, splits, considered_data):\n",
    "    #print \"Splitting data for feature: \"+feature\n",
    "    #print \"split is: \"\n",
    "    #print splits\n",
    "    data = []\n",
    "    for split in splits:\n",
    "        data.append([])\n",
    "    separate_buckets = {}\n",
    "    for data in considered_data:\n",
    "        feature_value = float(data.data_vars[feature])\n",
    "        if feature_value not in separate_buckets.keys():\n",
    "            new_list = []\n",
    "            new_list.append(data)\n",
    "            separate_buckets[feature_value] = new_list\n",
    "        else:\n",
    "            current_list = separate_buckets[feature_value]\n",
    "            current_list.append(data)\n",
    "            separate_buckets[feature_value] = current_list\n",
    "        \n",
    "    #splits = [{3.0: 152}, {6.0: 14}, {7.0: 16}]\n",
    "    #OR splits = [{3.0: 152}, [{6.0: 14}, {7.0: 16}]]\n",
    "            \n",
    "    new_data = []\n",
    "    for split in splits:\n",
    "        \n",
    "        #print \"Processing split: \", split\n",
    "        \n",
    "        # {0.0: 7}\n",
    "        # {1.0: 4, 2.0: 2, 3.0: 1}\n",
    "        \n",
    "        # Convert it to a list\n",
    "        split_list = []\n",
    "        if len(split) == 1:\n",
    "            \n",
    "            split_list.append(split)\n",
    "        else:\n",
    "            split_list.append(split)\n",
    "            '''\n",
    "            for each_value in split:\n",
    "                print \"Appending each value: \", each_value\n",
    "                split_list.append(each_value)\n",
    "            '''\n",
    "        \n",
    "        # Prepare a list for the data of that split\n",
    "        data_for_split = []\n",
    "        \n",
    "        # Get all the valid feature_values for that particular split\n",
    "        valid_feature_values = []\n",
    "        #print \"SPLIT LIST IN SPLIT DATA: \", split_list\n",
    "        for split_dict in split_list:\n",
    "            for feature_value_key in split_dict.keys():\n",
    "                valid_feature_values.append(feature_value_key)\n",
    "        \n",
    "        # Process the valid feature values, find matching data, and add it to the data for that split\n",
    "        for feature_value in valid_feature_values:\n",
    "            for data_pt in separate_buckets[feature_value]:\n",
    "                data_for_split.append(data_pt)\n",
    "        \n",
    "        # Add the data relevant for a certain split group to the new data array\n",
    "        new_data.append(data_for_split)\n",
    "        '''\n",
    "        if feature == \"number_of_major_vessels\":\n",
    "            print \"Length of data for split: \", len(data_for_split)\n",
    "            '''\n",
    "    '''\n",
    "    if feature == \"number_of_major_vessels\":\n",
    "        print \"Length of data returned for 1, 2, 3 : \", len(new_data[1])\n",
    "    '''\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Recurse to build the tree\n",
    "Used the information gain function to determine the best splits for each node of the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4177,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_tree(y, y_values, data, allowable_features_to_split_on):\n",
    "    info_gains = {}\n",
    "    split_yielding_max_info_gain = []\n",
    "    for feature in allowable_features_to_split_on:\n",
    "        if feature != y:\n",
    "            info_gain, split_yielding_max_info_gain = compute_best_split(y, y_values, feature, data)\n",
    "            info_gains[feature] = [info_gain, split_yielding_max_info_gain]\n",
    "\n",
    "    #print info_gains\n",
    "\n",
    "    # Printing out the information gains for each feature\n",
    "    '''\n",
    "    for feature in info_gains.keys():\n",
    "        print str(info_gains[feature][0])+\" : \"+feature\n",
    "    '''\n",
    "\n",
    "    # Find the maximum in the info_gains returned\n",
    "    max_info_gain = 0\n",
    "    best_split = []\n",
    "    best_feature = \"\"\n",
    "    \n",
    "    # Check if they are all equal to 0\n",
    "    counter = 0\n",
    "    total = 0\n",
    "    for feature in info_gains.keys():\n",
    "        if info_gains[feature][0] == 0:\n",
    "            counter += 1\n",
    "        total += 1\n",
    "    if counter == total:\n",
    "        return\n",
    "    \n",
    "    #print info_gains.keys()\n",
    "    for feature in info_gains.keys():\n",
    "        if info_gains[feature][0] > max_info_gain:\n",
    "            max_info_gain = info_gains[feature][0]\n",
    "            best_split = info_gains[feature][1]\n",
    "            best_feature = feature\n",
    "\n",
    "    #print max_info_gain\n",
    "    #print best_feature\n",
    "    # Split on that feature and optimal split\n",
    "    new_data = split_data(best_feature, best_split, data)\n",
    "\n",
    "    # Define the new y based on this data\n",
    "    y = feature\n",
    "    \n",
    "    #print best_split\n",
    "    return best_feature, new_data, best_split\n",
    "\n",
    "\n",
    "\n",
    "    # Now we have to feed that new data into the tree and branch off into the leaves\n",
    "    # so we have three groups for thal which means it should branch into three leaves:\n",
    "    # one with 3, one with 6, and one with 7.\n",
    "    # And recursively continue branching\n",
    "    \n",
    "    \n",
    "    \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4178,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the branch for:\n",
      "\t Feature =  thal\n",
      "\t Split   =  {3.0: 152}\n",
      "\t Length of New Data   =  152\n",
      "Allowable features to split on:  ['age', 'sex', 'chest_pain_type', 'resting_blood_pressure', 'serum_cholesterol', 'fasting_blood_sugar', 'resting_electrocardiographic_results', 'maximum_heart_rate_achieved', 'exercise_induced_angina', 'oldpeak', 'slope_peak_exercise', 'number_of_major_vessels', 'thal']\n",
      "Trying to remove:  thal\n",
      "Length of the data for the next call:  152\n",
      "*** Next Feature:\n",
      "chest_pain_type\n",
      "*** Next Best Split:\n",
      "[{1.0: 12}, {2.0: 33}, {3.0: 56}, {4.0: 51}]\n",
      "*** Length of Next New Data:\n",
      "4\n",
      "*   NODE  *\n",
      "\t splitting_feature:  thal\n",
      "\t feature_value:  [3.0]\n",
      "\t feature_value_occurrence:  152\n",
      "* CHILDREN *\n",
      "1 :\n",
      "\t splitting_feature:  chest_pain_type\n",
      "\t feature_value:  [1.0]\n",
      "\t feature_value_occurrence:  12\n",
      "2 :\n",
      "\t splitting_feature:  chest_pain_type\n",
      "\t feature_value:  [2.0]\n",
      "\t feature_value_occurrence:  33\n",
      "3 :\n",
      "\t splitting_feature:  chest_pain_type\n",
      "\t feature_value:  [3.0]\n",
      "\t feature_value_occurrence:  56\n",
      "4 :\n",
      "\t splitting_feature:  chest_pain_type\n",
      "\t feature_value:  [4.0]\n",
      "\t feature_value_occurrence:  51\n",
      "Processing the branch for:\n",
      "\t Feature =  thal\n",
      "\t Split   =  {6.0: 14}\n",
      "\t Length of New Data   =  14\n",
      "Allowable features to split on:  ['age', 'sex', 'chest_pain_type', 'resting_blood_pressure', 'serum_cholesterol', 'fasting_blood_sugar', 'resting_electrocardiographic_results', 'maximum_heart_rate_achieved', 'exercise_induced_angina', 'oldpeak', 'slope_peak_exercise', 'number_of_major_vessels', 'thal']\n",
      "Trying to remove:  thal\n",
      "Length of the data for the next call:  14\n",
      "*** Next Feature:\n",
      "number_of_major_vessels\n",
      "*** Next Best Split:\n",
      "[{0.0: 7}, {1.0: 4, 2.0: 2, 3.0: 1}]\n",
      "*** Length of Next New Data:\n",
      "2\n",
      "*   NODE  *\n",
      "\t splitting_feature:  thal\n",
      "\t feature_value:  [6.0]\n",
      "\t feature_value_occurrence:  14\n",
      "* CHILDREN *\n",
      "1 :\n",
      "\t splitting_feature:  number_of_major_vessels\n",
      "\t feature_value:  [0.0]\n",
      "\t feature_value_occurrence:  7\n",
      "2 :\n",
      "\t splitting_feature:  number_of_major_vessels\n",
      "\t feature_value:  [1.0, 2.0, 3.0]\n",
      "\t feature_value_occurrence:  7\n",
      "Processing the branch for:\n",
      "\t Feature =  thal\n",
      "\t Split   =  {7.0: 104}\n",
      "\t Length of New Data   =  104\n",
      "Allowable features to split on:  ['age', 'sex', 'chest_pain_type', 'resting_blood_pressure', 'serum_cholesterol', 'fasting_blood_sugar', 'resting_electrocardiographic_results', 'maximum_heart_rate_achieved', 'exercise_induced_angina', 'oldpeak', 'slope_peak_exercise', 'number_of_major_vessels', 'thal']\n",
      "Trying to remove:  thal\n",
      "Length of the data for the next call:  104\n",
      "*** Next Feature:\n",
      "chest_pain_type\n",
      "*** Next Best Split:\n",
      "[{1.0: 6}, {2.0: 7}, {3.0: 21}, {4.0: 70}]\n",
      "*** Length of Next New Data:\n",
      "4\n",
      "*   NODE  *\n",
      "\t splitting_feature:  thal\n",
      "\t feature_value:  [7.0]\n",
      "\t feature_value_occurrence:  104\n",
      "* CHILDREN *\n",
      "1 :\n",
      "\t splitting_feature:  chest_pain_type\n",
      "\t feature_value:  [1.0]\n",
      "\t feature_value_occurrence:  6\n",
      "2 :\n",
      "\t splitting_feature:  chest_pain_type\n",
      "\t feature_value:  [2.0]\n",
      "\t feature_value_occurrence:  7\n",
      "3 :\n",
      "\t splitting_feature:  chest_pain_type\n",
      "\t feature_value:  [3.0]\n",
      "\t feature_value_occurrence:  21\n",
      "4 :\n",
      "\t splitting_feature:  chest_pain_type\n",
      "\t feature_value:  [4.0]\n",
      "\t feature_value_occurrence:  70\n",
      "ASSIGNING NEW LEVELS\n",
      "Feature:  chest_pain_type\n",
      "Feature:  number_of_major_vessels\n",
      "Feature:  chest_pain_type\n",
      "Processing the branch for:\n",
      "\t Feature =  chest_pain_type\n",
      "\t Split   =  {1.0: 12}\n",
      "\t Length of New Data   =  12\n",
      "Allowable features to split on:  ['age', 'sex', 'chest_pain_type', 'resting_blood_pressure', 'serum_cholesterol', 'fasting_blood_sugar', 'resting_electrocardiographic_results', 'maximum_heart_rate_achieved', 'exercise_induced_angina', 'oldpeak', 'slope_peak_exercise', 'number_of_major_vessels', 'thal']\n",
      "Trying to remove:  chest_pain_type\n",
      "Length of the data for the next call:  12\n",
      "*** Next Feature:\n",
      "serum_cholesterol\n",
      "*** Next Best Split:\n",
      "[{226.0: 1, 234.0: 2, 239.0: 1, 240.0: 1, 211.0: 1, 244.0: 1, 213.0: 1, 182.0: 1}, {273.0: 1, 282.0: 1, 283.0: 1}]\n",
      "*** Length of Next New Data:\n",
      "2\n",
      "*   NODE  *\n",
      "\t splitting_feature:  chest_pain_type\n",
      "\t feature_value:  [1.0]\n",
      "\t feature_value_occurrence:  12\n",
      "* CHILDREN *\n",
      "1 :\n",
      "\t splitting_feature:  serum_cholesterol\n",
      "\t feature_value:  [226.0, 234.0, 239.0, 240.0, 211.0, 244.0, 213.0, 182.0]\n",
      "\t feature_value_occurrence:  9\n",
      "2 :\n",
      "\t splitting_feature:  serum_cholesterol\n",
      "\t feature_value:  [273.0, 282.0, 283.0]\n",
      "\t feature_value_occurrence:  3\n",
      "Processing the branch for:\n",
      "\t Feature =  chest_pain_type\n",
      "\t Split   =  {2.0: 33}\n",
      "\t Length of New Data   =  33\n",
      "Allowable features to split on:  ['age', 'sex', 'resting_blood_pressure', 'serum_cholesterol', 'fasting_blood_sugar', 'resting_electrocardiographic_results', 'maximum_heart_rate_achieved', 'exercise_induced_angina', 'oldpeak', 'slope_peak_exercise', 'number_of_major_vessels', 'thal', 'chest_pain_type']\n",
      "Trying to remove:  chest_pain_type\n",
      "Length of the data for the next call:  33\n",
      "*** Next Feature:\n",
      "oldpeak\n",
      "*** Next Best Split:\n",
      "[{0.0: 19, 0.4: 1, 0.2: 3, 0.8: 2, 0.6: 2, 1.1: 1, 1.3: 1, 0.7: 1, 1.4: 2}, {1.8: 1}]\n",
      "*** Length of Next New Data:\n",
      "2\n",
      "*   NODE  *\n",
      "\t splitting_feature:  chest_pain_type\n",
      "\t feature_value:  [2.0]\n",
      "\t feature_value_occurrence:  33\n",
      "* CHILDREN *\n",
      "1 :\n",
      "\t splitting_feature:  oldpeak\n",
      "\t feature_value:  [0.0, 0.4, 0.2, 0.8, 0.6, 1.1, 1.3, 0.7, 1.4]\n",
      "\t feature_value_occurrence:  32\n",
      "2 :\n",
      "\t splitting_feature:  oldpeak\n",
      "\t feature_value:  [1.8]\n",
      "\t feature_value_occurrence:  1\n",
      "Processing the branch for:\n",
      "\t Feature =  chest_pain_type\n",
      "\t Split   =  {3.0: 56}\n",
      "\t Length of New Data   =  56\n",
      "Allowable features to split on:  ['age', 'sex', 'resting_blood_pressure', 'serum_cholesterol', 'fasting_blood_sugar', 'resting_electrocardiographic_results', 'maximum_heart_rate_achieved', 'exercise_induced_angina', 'oldpeak', 'slope_peak_exercise', 'number_of_major_vessels', 'thal', 'chest_pain_type']\n",
      "Trying to remove:  chest_pain_type\n",
      "Length of the data for the next call:  56\n",
      "*** Next Feature:\n",
      "maximum_heart_rate_achieved\n",
      "*** Next Best Split:\n",
      "[{96.0: 1, 130.0: 1, 115.0: 1, 155.0: 1, 137.0: 1, 139.0: 1, 126.0: 1, 142.0: 1, 143.0: 1, 147.0: 1, 116.0: 1, 149.0: 2, 150.0: 1, 151.0: 1, 152.0: 3, 148.0: 1, 123.0: 1, 156.0: 1, 157.0: 3, 158.0: 3}, {160.0: 2, 162.0: 1, 163.0: 2, 165.0: 2, 166.0: 1, 167.0: 1, 168.0: 1, 169.0: 2, 170.0: 2, 172.0: 4, 173.0: 2, 174.0: 1, 175.0: 2, 179.0: 3, 180.0: 1, 182.0: 1, 187.0: 1}]\n",
      "*** Length of Next New Data:\n",
      "2\n",
      "*   NODE  *\n",
      "\t splitting_feature:  chest_pain_type\n",
      "\t feature_value:  [3.0]\n",
      "\t feature_value_occurrence:  56\n",
      "* CHILDREN *\n",
      "1 :\n",
      "\t splitting_feature:  maximum_heart_rate_achieved\n",
      "\t feature_value:  [96.0, 130.0, 115.0, 155.0, 137.0, 139.0, 126.0, 142.0, 143.0, 147.0, 116.0, 149.0, 150.0, 151.0, 152.0, 148.0, 123.0, 156.0, 157.0, 158.0]\n",
      "\t feature_value_occurrence:  27\n",
      "2 :\n",
      "\t splitting_feature:  maximum_heart_rate_achieved\n",
      "\t feature_value:  [160.0, 162.0, 163.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 172.0, 173.0, 174.0, 175.0, 179.0, 180.0, 182.0, 187.0]\n",
      "\t feature_value_occurrence:  29\n",
      "Processing the branch for:\n",
      "\t Feature =  chest_pain_type\n",
      "\t Split   =  {4.0: 51}\n",
      "\t Length of New Data   =  51\n",
      "Allowable features to split on:  ['age', 'sex', 'resting_blood_pressure', 'serum_cholesterol', 'fasting_blood_sugar', 'resting_electrocardiographic_results', 'maximum_heart_rate_achieved', 'exercise_induced_angina', 'oldpeak', 'slope_peak_exercise', 'number_of_major_vessels', 'thal', 'chest_pain_type']\n",
      "Trying to remove:  chest_pain_type\n",
      "Length of the data for the next call:  51\n",
      "*** Next Feature:\n",
      "number_of_major_vessels\n",
      "*** Next Best Split:\n",
      "[{0.0: 31}, {1.0: 10, 2.0: 6, 3.0: 4}]\n",
      "*** Length of Next New Data:\n",
      "2\n",
      "*   NODE  *\n",
      "\t splitting_feature:  chest_pain_type\n",
      "\t feature_value:  [4.0]\n",
      "\t feature_value_occurrence:  51\n",
      "* CHILDREN *\n",
      "1 :\n",
      "\t splitting_feature:  number_of_major_vessels\n",
      "\t feature_value:  [0.0]\n",
      "\t feature_value_occurrence:  31\n",
      "2 :\n",
      "\t splitting_feature:  number_of_major_vessels\n",
      "\t feature_value:  [1.0, 2.0, 3.0]\n",
      "\t feature_value_occurrence:  20\n",
      "Processing the branch for:\n",
      "\t Feature =  number_of_major_vessels\n",
      "\t Split   =  {0.0: 7}\n",
      "\t Length of New Data   =  7\n",
      "Allowable features to split on:  ['age', 'sex', 'resting_blood_pressure', 'serum_cholesterol', 'fasting_blood_sugar', 'resting_electrocardiographic_results', 'maximum_heart_rate_achieved', 'exercise_induced_angina', 'oldpeak', 'slope_peak_exercise', 'number_of_major_vessels', 'thal', 'chest_pain_type']\n",
      "Trying to remove:  number_of_major_vessels\n",
      "Length of the data for the next call:  7\n",
      "*** Next Feature:\n",
      "maximum_heart_rate_achieved\n",
      "*** Next Best Split:\n",
      "[{125.0: 1}, {132.0: 1, 138.0: 1, 148.0: 1, 190.0: 1, 150.0: 1, 126.0: 1}]\n",
      "*** Length of Next New Data:\n",
      "2\n",
      "*   NODE  *\n",
      "\t splitting_feature:  number_of_major_vessels\n",
      "\t feature_value:  [0.0]\n",
      "\t feature_value_occurrence:  7\n",
      "* CHILDREN *\n",
      "1 :\n",
      "\t splitting_feature:  maximum_heart_rate_achieved\n",
      "\t feature_value:  [125.0]\n",
      "\t feature_value_occurrence:  1\n",
      "2 :\n",
      "\t splitting_feature:  maximum_heart_rate_achieved\n",
      "\t feature_value:  [132.0, 138.0, 148.0, 190.0, 150.0, 126.0]\n",
      "\t feature_value_occurrence:  6\n",
      "Processing the branch for:\n",
      "\t Feature =  number_of_major_vessels\n",
      "\t Split   =  {1.0: 4, 2.0: 2, 3.0: 1}\n",
      "\t Length of New Data   =  7\n",
      "Allowable features to split on:  ['age', 'sex', 'resting_blood_pressure', 'serum_cholesterol', 'fasting_blood_sugar', 'resting_electrocardiographic_results', 'maximum_heart_rate_achieved', 'exercise_induced_angina', 'oldpeak', 'slope_peak_exercise', 'thal', 'chest_pain_type', 'number_of_major_vessels']\n",
      "Trying to remove:  number_of_major_vessels\n",
      "Length of the data for the next call:  7\n",
      "*** Next Feature:\n",
      "maximum_heart_rate_achieved\n",
      "*** Next Best Split:\n",
      "[{112.0: 1, 105.0: 1}, {120.0: 1, 132.0: 1, 142.0: 1, 134.0: 1, 158.0: 1}]\n",
      "*** Length of Next New Data:\n",
      "2\n",
      "*   NODE  *\n",
      "\t splitting_feature:  number_of_major_vessels\n",
      "\t feature_value:  [1.0, 2.0, 3.0]\n",
      "\t feature_value_occurrence:  7\n",
      "* CHILDREN *\n",
      "1 :\n",
      "\t splitting_feature:  maximum_heart_rate_achieved\n",
      "\t feature_value:  [112.0, 105.0]\n",
      "\t feature_value_occurrence:  2\n",
      "2 :\n",
      "\t splitting_feature:  maximum_heart_rate_achieved\n",
      "\t feature_value:  [120.0, 132.0, 142.0, 134.0, 158.0]\n",
      "\t feature_value_occurrence:  5\n",
      "Processing the branch for:\n",
      "\t Feature =  chest_pain_type\n",
      "\t Split   =  {1.0: 6}\n",
      "\t Length of New Data   =  6\n",
      "Allowable features to split on:  ['age', 'sex', 'resting_blood_pressure', 'serum_cholesterol', 'fasting_blood_sugar', 'resting_electrocardiographic_results', 'maximum_heart_rate_achieved', 'exercise_induced_angina', 'oldpeak', 'slope_peak_exercise', 'thal', 'chest_pain_type', 'number_of_major_vessels']\n",
      "Trying to remove:  chest_pain_type\n",
      "Length of the data for the next call:  6\n",
      "*** Next Feature:\n",
      "maximum_heart_rate_achieved\n",
      "*** Next Best Split:\n",
      "[{145.0: 1, 178.0: 2, 162.0: 1, 159.0: 1}, {182.0: 1}]\n",
      "*** Length of Next New Data:\n",
      "2\n",
      "*   NODE  *\n",
      "\t splitting_feature:  chest_pain_type\n",
      "\t feature_value:  [1.0]\n",
      "\t feature_value_occurrence:  6\n",
      "* CHILDREN *\n",
      "1 :\n",
      "\t splitting_feature:  maximum_heart_rate_achieved\n",
      "\t feature_value:  [145.0, 178.0, 162.0, 159.0]\n",
      "\t feature_value_occurrence:  5\n",
      "2 :\n",
      "\t splitting_feature:  maximum_heart_rate_achieved\n",
      "\t feature_value:  [182.0]\n",
      "\t feature_value_occurrence:  1\n",
      "Processing the branch for:\n",
      "\t Feature =  chest_pain_type\n",
      "\t Split   =  {2.0: 7}\n",
      "\t Length of New Data   =  7\n",
      "Allowable features to split on:  ['age', 'sex', 'resting_blood_pressure', 'serum_cholesterol', 'fasting_blood_sugar', 'resting_electrocardiographic_results', 'maximum_heart_rate_achieved', 'exercise_induced_angina', 'oldpeak', 'slope_peak_exercise', 'thal', 'number_of_major_vessels', 'chest_pain_type']\n",
      "Trying to remove:  chest_pain_type\n",
      "Length of the data for the next call:  7\n",
      "*** Next Feature:\n",
      "oldpeak\n",
      "*** Next Best Split:\n",
      "[{0.0: 4}, {1.4: 1, 0.3: 1, 1.0: 1}]\n",
      "*** Length of Next New Data:\n",
      "2\n",
      "*   NODE  *\n",
      "\t splitting_feature:  chest_pain_type\n",
      "\t feature_value:  [2.0]\n",
      "\t feature_value_occurrence:  7\n",
      "* CHILDREN *\n",
      "1 :\n",
      "\t splitting_feature:  oldpeak\n",
      "\t feature_value:  [0.0]\n",
      "\t feature_value_occurrence:  4\n",
      "2 :\n",
      "\t splitting_feature:  oldpeak\n",
      "\t feature_value:  [1.4, 0.3, 1.0]\n",
      "\t feature_value_occurrence:  3\n",
      "Processing the branch for:\n",
      "\t Feature =  chest_pain_type\n",
      "\t Split   =  {3.0: 21}\n",
      "\t Length of New Data   =  21\n",
      "Allowable features to split on:  ['age', 'sex', 'resting_blood_pressure', 'serum_cholesterol', 'fasting_blood_sugar', 'resting_electrocardiographic_results', 'maximum_heart_rate_achieved', 'exercise_induced_angina', 'oldpeak', 'slope_peak_exercise', 'thal', 'number_of_major_vessels', 'chest_pain_type']\n",
      "Trying to remove:  chest_pain_type\n",
      "Length of the data for the next call:  21\n",
      "*** Next Feature:\n",
      "oldpeak\n",
      "*** Next Best Split:\n",
      "[{0.0: 1, 1.0: 1, 0.2: 2, 1.6: 3, 0.4: 2, 0.6: 2, 1.2: 1, 0.8: 1, 1.8: 2, 0.5: 1}, {2.5: 1, 2.0: 2, 2.9: 1, 3.2: 1}]\n",
      "*** Length of Next New Data:\n",
      "2\n",
      "*   NODE  *\n",
      "\t splitting_feature:  chest_pain_type\n",
      "\t feature_value:  [3.0]\n",
      "\t feature_value_occurrence:  21\n",
      "* CHILDREN *\n",
      "1 :\n",
      "\t splitting_feature:  oldpeak\n",
      "\t feature_value:  [0.0, 1.0, 0.2, 1.6, 0.4, 0.6, 1.2, 0.8, 1.8, 0.5]\n",
      "\t feature_value_occurrence:  16\n",
      "2 :\n",
      "\t splitting_feature:  oldpeak\n",
      "\t feature_value:  [2.5, 2.0, 2.9, 3.2]\n",
      "\t feature_value_occurrence:  5\n",
      "Processing the branch for:\n",
      "\t Feature =  chest_pain_type\n",
      "\t Split   =  {4.0: 70}\n",
      "\t Length of New Data   =  70\n",
      "Allowable features to split on:  ['age', 'sex', 'resting_blood_pressure', 'serum_cholesterol', 'fasting_blood_sugar', 'resting_electrocardiographic_results', 'maximum_heart_rate_achieved', 'exercise_induced_angina', 'oldpeak', 'slope_peak_exercise', 'thal', 'number_of_major_vessels', 'chest_pain_type']\n",
      "Trying to remove:  chest_pain_type\n",
      "Length of the data for the next call:  70\n",
      "*** Next Feature:\n",
      "oldpeak\n",
      "*** Next Best Split:\n",
      "[{0.5: 2, 0.0: 11, 0.2: 2, 0.4: 1, 0.1: 2}, {2.5: 1, 1.0: 5, 2.0: 3, 3.0: 2, 4.0: 2, 1.9: 2, 4.2: 1, 2.8: 4, 5.6: 1, 3.4: 1, 3.6: 1, 0.9: 1, 6.2: 1, 1.2: 6, 2.4: 1, 0.8: 3, 1.4: 4, 2.2: 2, 1.6: 3, 1.8: 3, 2.6: 4, 3.1: 1}]\n",
      "*** Length of Next New Data:\n",
      "2\n",
      "*   NODE  *\n",
      "\t splitting_feature:  chest_pain_type\n",
      "\t feature_value:  [4.0]\n",
      "\t feature_value_occurrence:  70\n",
      "* CHILDREN *\n",
      "1 :\n",
      "\t splitting_feature:  oldpeak\n",
      "\t feature_value:  [0.5, 0.0, 0.2, 0.4, 0.1]\n",
      "\t feature_value_occurrence:  18\n",
      "2 :\n",
      "\t splitting_feature:  oldpeak\n",
      "\t feature_value:  [2.5, 1.0, 2.0, 3.0, 4.0, 1.9, 4.2, 2.8, 5.6, 3.4, 3.6, 0.9, 6.2, 1.2, 2.4, 0.8, 1.4, 2.2, 1.6, 1.8, 2.6, 3.1]\n",
      "\t feature_value_occurrence:  52\n",
      "ASSIGNING NEW LEVELS\n",
      "Feature:  serum_cholesterol\n",
      "FLAG serum_cholesterol as finished!!!\n",
      "Feature:  oldpeak\n",
      "FLAG oldpeak as finished!!!\n",
      "Feature:  maximum_heart_rate_achieved\n",
      "Feature:  number_of_major_vessels\n",
      "Feature:  maximum_heart_rate_achieved\n",
      "FLAG maximum_heart_rate_achieved as finished!!!\n",
      "Feature:  maximum_heart_rate_achieved\n",
      "FLAG maximum_heart_rate_achieved as finished!!!\n",
      "FLAG maximum_heart_rate_achieved as finished!!!\n",
      "Feature:  maximum_heart_rate_achieved\n",
      "FLAG maximum_heart_rate_achieved as finished!!!\n",
      "FLAG maximum_heart_rate_achieved as finished!!!\n",
      "Feature:  oldpeak\n",
      "FLAG oldpeak as finished!!!\n",
      "FLAG oldpeak as finished!!!\n",
      "Feature:  oldpeak\n",
      "FLAG oldpeak as finished!!!\n",
      "Feature:  oldpeak\n",
      "Processing the branch for:\n",
      "\t Feature =  serum_cholesterol\n",
      "\t Split   =  {226.0: 1, 234.0: 2, 239.0: 1, 240.0: 1, 211.0: 1, 244.0: 1, 213.0: 1, 182.0: 1}\n",
      "\t Length of New Data   =  9\n",
      "Allowable features to split on:  ['age', 'sex', 'resting_blood_pressure', 'serum_cholesterol', 'fasting_blood_sugar', 'resting_electrocardiographic_results', 'maximum_heart_rate_achieved', 'exercise_induced_angina', 'oldpeak', 'slope_peak_exercise', 'thal', 'number_of_major_vessels', 'chest_pain_type']\n",
      "Trying to remove:  serum_cholesterol\n",
      "Length of the data for the next call:  9\n",
      "*** Next Feature:\n",
      "oldpeak\n",
      "*** Next Best Split:\n",
      "[{0.0: 1, 0.1: 1, 0.8: 1, 1.8: 2, 0.9: 1, 1.4: 1}, {2.6: 2}]\n",
      "*** Length of Next New Data:\n",
      "2\n",
      "*   NODE  *\n",
      "\t splitting_feature:  serum_cholesterol\n",
      "\t feature_value:  [226.0, 234.0, 239.0, 240.0, 211.0, 244.0, 213.0, 182.0]\n",
      "\t feature_value_occurrence:  9\n",
      "* CHILDREN *\n",
      "1 :\n",
      "\t splitting_feature:  oldpeak\n",
      "\t feature_value:  [0.0, 0.1, 0.8, 1.8, 0.9, 1.4]\n",
      "\t feature_value_occurrence:  7\n",
      "2 :\n",
      "\t splitting_feature:  oldpeak\n",
      "\t feature_value:  [2.6]\n",
      "\t feature_value_occurrence:  2\n",
      "Processing the branch for:\n",
      "\t Feature =  serum_cholesterol\n",
      "\t Split   =  {273.0: 1, 282.0: 1, 283.0: 1}\n",
      "\t Length of New Data   =  3\n",
      "Allowable features to split on:  ['age', 'sex', 'resting_blood_pressure', 'fasting_blood_sugar', 'resting_electrocardiographic_results', 'maximum_heart_rate_achieved', 'exercise_induced_angina', 'oldpeak', 'slope_peak_exercise', 'thal', 'number_of_major_vessels', 'chest_pain_type', 'serum_cholesterol']\n",
      "Trying to remove:  serum_cholesterol\n",
      "Length of the data for the next call:  3\n",
      "Skipping call for:  serum_cholesterol\n",
      "where split is  {273.0: 1, 282.0: 1, 283.0: 1}\n",
      " and data length is  3\n",
      "*   NODE  *\n",
      "\t splitting_feature:  serum_cholesterol\n",
      "\t feature_value:  [273.0, 282.0, 283.0]\n",
      "\t feature_value_occurrence:  3\n",
      "* CHILDREN *\n",
      "Processing the branch for:\n",
      "\t Feature =  oldpeak\n",
      "\t Split   =  {0.0: 19, 0.4: 1, 0.2: 3, 0.8: 2, 0.6: 2, 1.1: 1, 1.3: 1, 0.7: 1, 1.4: 2}\n",
      "\t Length of New Data   =  32\n",
      "Allowable features to split on:  ['age', 'sex', 'resting_blood_pressure', 'fasting_blood_sugar', 'resting_electrocardiographic_results', 'maximum_heart_rate_achieved', 'exercise_induced_angina', 'oldpeak', 'slope_peak_exercise', 'thal', 'number_of_major_vessels', 'chest_pain_type']\n",
      "Trying to remove:  oldpeak\n",
      "Length of the data for the next call:  32\n",
      "*** Next Feature:\n",
      "number_of_major_vessels\n",
      "*** Next Best Split:\n",
      "[{0.0: 25, 1.0: 4}, {2.0: 3}]\n",
      "*** Length of Next New Data:\n",
      "2\n",
      "*   NODE  *\n",
      "\t splitting_feature:  oldpeak\n",
      "\t feature_value:  [0.0, 0.4, 0.2, 0.8, 0.6, 1.1, 1.3, 0.7, 1.4]\n",
      "\t feature_value_occurrence:  32\n",
      "* CHILDREN *\n",
      "1 :\n",
      "\t splitting_feature:  number_of_major_vessels\n",
      "\t feature_value:  [0.0, 1.0]\n",
      "\t feature_value_occurrence:  29\n",
      "2 :\n",
      "\t splitting_feature:  number_of_major_vessels\n",
      "\t feature_value:  [2.0]\n",
      "\t feature_value_occurrence:  3\n",
      "Processing the branch for:\n",
      "\t Feature =  oldpeak\n",
      "\t Split   =  {1.8: 1}\n",
      "\t Length of New Data   =  1\n",
      "Allowable features to split on:  ['age', 'sex', 'resting_blood_pressure', 'fasting_blood_sugar', 'resting_electrocardiographic_results', 'maximum_heart_rate_achieved', 'exercise_induced_angina', 'slope_peak_exercise', 'thal', 'number_of_major_vessels', 'chest_pain_type', 'oldpeak']\n",
      "Trying to remove:  oldpeak\n",
      "Length of the data for the next call:  1\n",
      "Skipping call for:  oldpeak\n",
      "where split is  {1.8: 1}\n",
      " and data length is  1\n",
      "*   NODE  *\n",
      "\t splitting_feature:  oldpeak\n",
      "\t feature_value:  [1.8]\n",
      "\t feature_value_occurrence:  1\n",
      "* CHILDREN *\n",
      "Processing the branch for:\n",
      "\t Feature =  maximum_heart_rate_achieved\n",
      "\t Split   =  {96.0: 1, 130.0: 1, 115.0: 1, 155.0: 1, 137.0: 1, 139.0: 1, 126.0: 1, 142.0: 1, 143.0: 1, 147.0: 1, 116.0: 1, 149.0: 2, 150.0: 1, 151.0: 1, 152.0: 3, 148.0: 1, 123.0: 1, 156.0: 1, 157.0: 3, 158.0: 3}\n",
      "\t Length of New Data   =  27\n",
      "Allowable features to split on:  ['age', 'sex', 'resting_blood_pressure', 'fasting_blood_sugar', 'resting_electrocardiographic_results', 'maximum_heart_rate_achieved', 'exercise_induced_angina', 'slope_peak_exercise', 'thal', 'number_of_major_vessels', 'chest_pain_type']\n",
      "Trying to remove:  maximum_heart_rate_achieved\n",
      "Length of the data for the next call:  27\n",
      "*** Next Feature:\n",
      "sex\n",
      "*** Next Best Split:\n",
      "[{0.0: 14}, {1.0: 13}]\n",
      "*** Length of Next New Data:\n",
      "2\n",
      "*   NODE  *\n",
      "\t splitting_feature:  maximum_heart_rate_achieved\n",
      "\t feature_value:  [96.0, 130.0, 115.0, 155.0, 137.0, 139.0, 126.0, 142.0, 143.0, 147.0, 116.0, 149.0, 150.0, 151.0, 152.0, 148.0, 123.0, 156.0, 157.0, 158.0]\n",
      "\t feature_value_occurrence:  27\n",
      "* CHILDREN *\n",
      "1 :\n",
      "\t splitting_feature:  sex\n",
      "\t feature_value:  [0.0]\n",
      "\t feature_value_occurrence:  14\n",
      "2 :\n",
      "\t splitting_feature:  sex\n",
      "\t feature_value:  [1.0]\n",
      "\t feature_value_occurrence:  13\n",
      "Processing the branch for:\n",
      "\t Feature =  maximum_heart_rate_achieved\n",
      "\t Split   =  {160.0: 2, 162.0: 1, 163.0: 2, 165.0: 2, 166.0: 1, 167.0: 1, 168.0: 1, 169.0: 2, 170.0: 2, 172.0: 4, 173.0: 2, 174.0: 1, 175.0: 2, 179.0: 3, 180.0: 1, 182.0: 1, 187.0: 1}\n",
      "\t Length of New Data   =  29\n",
      "Allowable features to split on:  ['age', 'sex', 'resting_blood_pressure', 'fasting_blood_sugar', 'resting_electrocardiographic_results', 'exercise_induced_angina', 'slope_peak_exercise', 'thal', 'number_of_major_vessels', 'chest_pain_type', 'maximum_heart_rate_achieved']\n",
      "Trying to remove:  maximum_heart_rate_achieved\n",
      "Length of the data for the next call:  29\n",
      "*** Next Feature:\n",
      "exercise_induced_angina\n",
      "*** Next Best Split:\n",
      "[{0.0: 26}, {1.0: 3}]\n",
      "*** Length of Next New Data:\n",
      "2\n",
      "*   NODE  *\n",
      "\t splitting_feature:  maximum_heart_rate_achieved\n",
      "\t feature_value:  [160.0, 162.0, 163.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 172.0, 173.0, 174.0, 175.0, 179.0, 180.0, 182.0, 187.0]\n",
      "\t feature_value_occurrence:  29\n",
      "* CHILDREN *\n",
      "1 :\n",
      "\t splitting_feature:  exercise_induced_angina\n",
      "\t feature_value:  [0.0]\n",
      "\t feature_value_occurrence:  26\n",
      "2 :\n",
      "\t splitting_feature:  exercise_induced_angina\n",
      "\t feature_value:  [1.0]\n",
      "\t feature_value_occurrence:  3\n",
      "Processing the branch for:\n",
      "\t Feature =  number_of_major_vessels\n",
      "\t Split   =  {0.0: 31}\n",
      "\t Length of New Data   =  31\n",
      "Allowable features to split on:  ['age', 'sex', 'resting_blood_pressure', 'fasting_blood_sugar', 'resting_electrocardiographic_results', 'exercise_induced_angina', 'slope_peak_exercise', 'thal', 'number_of_major_vessels', 'chest_pain_type', 'maximum_heart_rate_achieved']\n",
      "Trying to remove:  number_of_major_vessels\n",
      "Length of the data for the next call:  31\n",
      "*** Next Feature:\n",
      "age\n",
      "*** Next Best Split:\n",
      "[{35.0: 1, 42.0: 2, 43.0: 2, 45.0: 3, 46.0: 1, 47.0: 1, 48.0: 1, 49.0: 1, 50.0: 1, 51.0: 1, 53.0: 2, 54.0: 1}, {64.0: 1, 66.0: 1, 67.0: 1, 71.0: 1, 55.0: 1, 57.0: 1, 58.0: 1, 59.0: 2, 60.0: 1, 61.0: 1, 62.0: 3}]\n",
      "*** Length of Next New Data:\n",
      "2\n",
      "*   NODE  *\n",
      "\t splitting_feature:  number_of_major_vessels\n",
      "\t feature_value:  [0.0]\n",
      "\t feature_value_occurrence:  31\n",
      "* CHILDREN *\n",
      "1 :\n",
      "\t splitting_feature:  age\n",
      "\t feature_value:  [35.0, 42.0, 43.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 53.0, 54.0]\n",
      "\t feature_value_occurrence:  17\n",
      "2 :\n",
      "\t splitting_feature:  age\n",
      "\t feature_value:  [64.0, 66.0, 67.0, 71.0, 55.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0]\n",
      "\t feature_value_occurrence:  14\n",
      "Processing the branch for:\n",
      "\t Feature =  number_of_major_vessels\n",
      "\t Split   =  {1.0: 10, 2.0: 6, 3.0: 4}\n",
      "\t Length of New Data   =  20\n",
      "Allowable features to split on:  ['age', 'sex', 'resting_blood_pressure', 'fasting_blood_sugar', 'resting_electrocardiographic_results', 'exercise_induced_angina', 'slope_peak_exercise', 'thal', 'chest_pain_type', 'maximum_heart_rate_achieved', 'number_of_major_vessels']\n",
      "Trying to remove:  number_of_major_vessels\n",
      "Length of the data for the next call:  20\n",
      "*** Next Feature:\n",
      "sex\n",
      "*** Next Best Split:\n",
      "[{0.0: 6}, {1.0: 14}]\n",
      "*** Length of Next New Data:\n",
      "2\n",
      "*   NODE  *\n",
      "\t splitting_feature:  number_of_major_vessels\n",
      "\t feature_value:  [1.0, 2.0, 3.0]\n",
      "\t feature_value_occurrence:  20\n",
      "* CHILDREN *\n",
      "1 :\n",
      "\t splitting_feature:  sex\n",
      "\t feature_value:  [0.0]\n",
      "\t feature_value_occurrence:  6\n",
      "2 :\n",
      "\t splitting_feature:  sex\n",
      "\t feature_value:  [1.0]\n",
      "\t feature_value_occurrence:  14\n",
      "Processing the branch for:\n",
      "\t Feature =  maximum_heart_rate_achieved\n",
      "\t Split   =  {125.0: 1}\n",
      "\t Length of New Data   =  1\n",
      "Allowable features to split on:  ['age', 'sex', 'resting_blood_pressure', 'fasting_blood_sugar', 'resting_electrocardiographic_results', 'exercise_induced_angina', 'slope_peak_exercise', 'thal', 'chest_pain_type', 'maximum_heart_rate_achieved', 'number_of_major_vessels']\n",
      "Trying to remove:  maximum_heart_rate_achieved\n",
      "Length of the data for the next call:  1\n",
      "Skipping call for:  maximum_heart_rate_achieved\n",
      "where split is  {125.0: 1}\n",
      " and data length is  1\n",
      "*   NODE  *\n",
      "\t splitting_feature:  maximum_heart_rate_achieved\n",
      "\t feature_value:  [125.0]\n",
      "\t feature_value_occurrence:  1\n",
      "* CHILDREN *\n",
      "Processing the branch for:\n",
      "\t Feature =  maximum_heart_rate_achieved\n",
      "\t Split   =  {132.0: 1, 138.0: 1, 148.0: 1, 190.0: 1, 150.0: 1, 126.0: 1}\n",
      "\t Length of New Data   =  6\n",
      "Allowable features to split on:  ['age', 'sex', 'resting_blood_pressure', 'fasting_blood_sugar', 'resting_electrocardiographic_results', 'exercise_induced_angina', 'slope_peak_exercise', 'thal', 'chest_pain_type', 'number_of_major_vessels']\n",
      "Trying to remove:  maximum_heart_rate_achieved\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "list.remove(x): x not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4178-a51315e5e463>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Allowable features to split on: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowable_features_to_split_on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Trying to remove: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                 \u001b[0mallowable_features_to_split_on\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m             \u001b[0;31m# Call build_tree for next partition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;31m#print \"Allowable_features_to_split_on:\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: list.remove(x): x not in list"
     ]
    }
   ],
   "source": [
    "y = \"has_heart_disease\"\n",
    "allowable_features_to_split_on = data.data_vars.keys()\n",
    "\n",
    "feature, new_data, best_split = build_tree(y, [2, 1], total_data_array, allowable_features_to_split_on)\n",
    "levels = []\n",
    "levels.append([feature, new_data, best_split])\n",
    "#print best_split\n",
    "#print \"Length of new data \", len(new_data)\n",
    "possible_y_vals_array = []\n",
    "for split in best_split:\n",
    "    new_list = []\n",
    "    for y_val in split.keys():\n",
    "        new_list.append(y_val)\n",
    "    possible_y_vals_array.append(new_list)\n",
    "    \n",
    "# Edit the features allowed to split on\n",
    "\n",
    "'''\n",
    "for data in new_data[1]:\n",
    "    print data.data_vars[\"sex\"]\n",
    "'''\n",
    "\n",
    "allowable_features_to_split_on.remove(\"has_heart_disease\")\n",
    "    \n",
    "\n",
    "\n",
    "tree_array = []\n",
    "# Process each feature \n",
    "# level = [0: feature, 1: new_data, 2: best_split]\n",
    "new_levels = []\n",
    "tree_is_finished = False\n",
    "processed = 0\n",
    "while not tree_is_finished:\n",
    "    \n",
    "    for level in levels:\n",
    "        '''\n",
    "        feature = level[0]\n",
    "        for level in levels:\n",
    "            print level[0]\n",
    "        print \"Processing feature: \", level[0]\n",
    "        new_data = level[1]\n",
    "        best_split = level[2]\n",
    "        print \"Split is : \", best_split\n",
    "        print 'Length of New Data',len(new_data)\n",
    "        '''\n",
    "        \n",
    "        \n",
    "\n",
    "        # Process each split for the feature\n",
    "        for branch_index in range(len(level[1])):\n",
    "            \n",
    "            #for split in level[2]:\n",
    "            #print \"New Node:\"\n",
    "            #print \"\\t splitting_feature: \", level[0]\n",
    "            #print \"\\t feature_value: \", level[2][branch_index].keys()\n",
    "            #print \"\\t feature_value_occurrence: \", sum(level[2][branch_index].values())\n",
    "            current_leaf = Node(level[0], level[2][branch_index].keys(), sum(level[2][branch_index].values()),level[1][branch_index])\n",
    "            tree_array.append(current_leaf)\n",
    "            \n",
    "            print \"Processing the branch for:\"\n",
    "            print \"\\t Feature = \", level[0]\n",
    "            print \"\\t Split   = \", level[2][branch_index]\n",
    "            data_for_next_call = level[1][branch_index]\n",
    "            print \"\\t Length of New Data   = \", len(data_for_next_call)\n",
    "            '''\n",
    "            if len(level[2][branch_index]) > 1:\n",
    "                data_for_next_call = level[1][branch_index]\n",
    "                print\n",
    "            else: \n",
    "                print \"\\t Length of New Data   = \", len(level[1][branch_index][0])\n",
    "            '''\n",
    "            # Edit the allowable features to split on since if you split on a nominal feature and only have \n",
    "            # one value for that nominal feature in the branch, you shouldn't split on it again\n",
    "            if features_and_types[feature] == \"nominal\" and len(possible_y_vals_array[0]) == 1 and level[0] in allowable_features_to_split_on:\n",
    "                print \"Allowable features to split on: \", allowable_features_to_split_on\n",
    "                print \"Trying to remove: \", level[0]\n",
    "                allowable_features_to_split_on.remove(level[0])\n",
    "            # Call build_tree for next partition\n",
    "            #print \"Allowable_features_to_split_on:\"\n",
    "            #print allowable_features_to_split_on\n",
    "            #print \"y is : \"+feature\n",
    "            if len(allowable_features_to_split_on) != 0:\n",
    "                #print \"Possible_y_vals:\"\n",
    "                #print possible_y_vals_array\n",
    "                #print \"branch index: \"+str(branch_index)\n",
    "\n",
    "\n",
    "                \n",
    "                print \"Length of the data for the next call: \", len(data_for_next_call)\n",
    "                if len(data_for_next_call) > 5:\n",
    "\n",
    "                    possible_y_values = []\n",
    "                    for pt in data_for_next_call:\n",
    "                            y_value = pt.data_vars[level[0]]\n",
    "                            if y_value not in possible_y_values:\n",
    "                                possible_y_values.append(y_value)\n",
    "\n",
    "                    #print \"Allowable features to split on:\"\n",
    "                    #print allowable_features_to_split_on\n",
    "                    #print \"Level[0]\"\n",
    "                    #print level[0]\n",
    "                    #print \"Possible y values:\"\n",
    "                    #print possible_y_values\n",
    "                    #print \"new data of branch index:\"\n",
    "                    #print new_data[branch_index]\n",
    "\n",
    "                    '''\n",
    "                    if level[0] == \"chest_pain_type\":\n",
    "                        for data in data_for_next_call:\n",
    "                            print_data(data)\n",
    "                    '''\n",
    "\n",
    "                    next_feature, next_new_data, next_best_split = build_tree(level[0], possible_y_values, data_for_next_call, allowable_features_to_split_on)\n",
    "\n",
    "                    print \"*** Next Feature:\"\n",
    "                    print next_feature\n",
    "                    #print \"*** Next New Data:\"\n",
    "                    #print next_new_data\n",
    "                    print \"*** Next Best Split:\"\n",
    "                    print next_best_split\n",
    "                    print \"*** Length of Next New Data:\"\n",
    "                    print len(next_new_data)\n",
    "\n",
    "                    # Add the children for the current leaf\n",
    "                    for child_index in range(len(next_new_data)):\n",
    "                        child_splitting_feature = next_feature\n",
    "                        child_feature_value = next_best_split[child_index].keys()\n",
    "                        child_feature_value_occurrence = sum(next_best_split[child_index].values())\n",
    "                        child = Node(child_splitting_feature, child_feature_value, child_feature_value_occurrence,next_new_data)\n",
    "                        current_leaf.add_child(child)\n",
    "\n",
    "                    new_levels.append([next_feature, next_new_data, next_best_split])\n",
    "\n",
    "\n",
    "                    # Put feature back in allowable features because it's possible we might need it later\n",
    "                    allowable_features_to_split_on.append(level[0])\n",
    "                else:\n",
    "                    print \"Skipping call for: \", level[0]\n",
    "                    print \"where split is \", level[2][branch_index]\n",
    "                    print \" and data length is \", len(data_for_next_call)\n",
    "            current_leaf.print_node_and_children()\n",
    "        \n",
    "    # Levels has finished processing\n",
    "    '''\n",
    "    for level in levels:\n",
    "        # Each node is structured:\n",
    "            # 1. splitting_feature\n",
    "            # 2. feature_value\n",
    "            # 3. feature_value_occurrence\n",
    "        for split in level[2]:\n",
    "            print \"New Node:\"\n",
    "            print \"\\t splitting_feature: \", level[0]\n",
    "            print \"\\t feature_value: \", split.keys()\n",
    "            print \"\\t feature_value_occurrence: \", sum(split.values())\n",
    "            tree_array.append(Node(level[0], split.keys(), split.values()))\n",
    "    '''\n",
    "    '''\n",
    "    for node in tree_array:\n",
    "        print \"new Node:\"\n",
    "        print node.splitting_feature\n",
    "        print node.feature_value\n",
    "    '''\n",
    "    '''\n",
    "    print \"NEW LEVELS:\"\n",
    "    for e in new_levels:\n",
    "        print \"Level: \",e[0]\n",
    "        print \"Length of Data: \",len(e[1])        \n",
    "        print \"Split: \",e[2]\n",
    "    '''\n",
    "    del levels[:]\n",
    "    \n",
    "    # Set the levels equal to everything in the new_levels\n",
    "    for s in new_levels:\n",
    "        levels.append(s)\n",
    "        \n",
    "    # Also delete the ones you've processed in new_levels\n",
    "    \n",
    "    del levels[0:processed*3]\n",
    "        \n",
    "    \n",
    "    print \"ASSIGNING NEW LEVELS\"\n",
    "    for e in levels:\n",
    "        print \"Feature: \", e[0]\n",
    "        for data_list in e[1]:\n",
    "            if len(data_list) <= 5:\n",
    "                print \"FLAG \"+e[0]+\" as finished!!!\"\n",
    "        \n",
    "    \n",
    "    processed += 1\n",
    "    if processed == 3:\n",
    "        print \n",
    "        break\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
